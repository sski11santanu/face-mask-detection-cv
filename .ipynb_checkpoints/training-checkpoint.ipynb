{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4ec739b-535f-441f-b58b-914ed27e1be9",
   "metadata": {},
   "source": [
    "# Load the Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d1fe08-5938-4295-90db-bff1094508c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The size of images after they'll be resized\n",
    "IMG_SIZE = 50\n",
    "# Path to the folder containing both types of images\n",
    "MASTER_PATH = \"dataset\"\n",
    "# The names of the types and the corresponding label encoding\n",
    "CATEGORIES = {\"with mask\" : 1, \"without mask\" : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71358d2b-3762-407c-85ce-29831bf7d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e7491d2-f1a6-4c26-9099-5a7d6e8c96a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return the pre-processed form of each image\n",
    "def preprocessImage(img):\n",
    "    # Turn into grayscale form\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Resize\n",
    "    resized = cv2.resize(gray, (IMG_SIZE, IMG_SIZE))\n",
    "    # Reshape to make it compatible with the CNN (2D) model\n",
    "    reshaped = resized.reshape(*resized.shape, 1)\n",
    "    return reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fb844af-93ca-4709-a566-c967fe65224c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1376, 50, 50, 1), (1376, 2))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empty lists for storing processed images and their corresponding labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for cat, label in CATEGORIES.items():\n",
    "    # Get the path of the images belonging to the current category\n",
    "    imgPath = os.path.join(MASTER_PATH, cat)\n",
    "    # Get the list of the names (with extensions) of images\n",
    "    imgNames = os.listdir(imgPath)\n",
    "    for imgName in imgNames:\n",
    "        # List which denotes the current label (the index for which the value is 1 denotes the label)\n",
    "        l = [0, 0]\n",
    "        l[label] = 1\n",
    "        # Location of the current image\n",
    "        imgLoc = os.path.join(imgPath, imgName)\n",
    "        img = cv2.imread(imgLoc)\n",
    "        # Push the image as well as the label to the respective lists\n",
    "        images.append(preprocessImage(img))\n",
    "        labels.append(l)\n",
    "        \n",
    "# Convert to numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "# Check the shapes\n",
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4631c90d-fd34-44fd-a716-6a6d0ce9689a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('uint8'), dtype('int32'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dtypes\n",
    "images.dtype, labels.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8241a3e1-ffd6-4667-8af3-9ebb6123bd35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((690, 2), (686, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the count of entries belonging to each label\n",
    "msk = np.array([True if row[1] == 1 else False for row in labels])\n",
    "labels[msk].shape, labels[~msk].shape  # Should be ((690, 2), (686, 2)), i.e., 690 with mask and rest without mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d22e9f8-251f-4a3c-b0da-e9db2b6716e6",
   "metadata": {},
   "source": [
    "# Building the CNN 2D Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb4132d0-13da-48cb-a1f3-2439e952a1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Activation, Flatten, Dropout, MaxPooling2D\n",
    "# Function to checkpoint at the epoch when the model performs the best\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cab1e5a-7b9e-4ee1-9393-b98918f616ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model in the sequential mode\n",
    "model = Sequential()\n",
    "# Add the input layer with 50 kernels each of shape (3, 3)\n",
    "model.add(Conv2D(50, (3, 3), input_shape = images[0].shape))\n",
    "# Input activation layer\n",
    "model.add(Activation(\"relu\"))\n",
    "# Max pooling layer for down sampling and highlighting the most present features\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# First hidden layer (similar) with 50 kernels\n",
    "model.add(Conv2D(50, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# A flatten and a dropout layer for stacking and preventing overfitting\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "# 2nd hidden layer, a 50 neurons dense one\n",
    "model.add(Dense(50, activation = \"relu\"))\n",
    "# Output layer\n",
    "model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "# Compile\n",
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e8c11b9-bcb6-498a-a8a2-0a69d49cea11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 50)        500       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 48, 48, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 24, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 22, 22, 50)        22550     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 22, 22, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 50)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6050)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 6050)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                302550    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 325,702\n",
      "Trainable params: 325,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarise the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974b847f-4b54-4c1d-9b9d-525c9c48030c",
   "metadata": {},
   "source": [
    "# Splitting Data and Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65c1f50b-b515-4d25-bb38-305ea2fcc96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5679e467-f76d-4b17-aa6f-eaa283bc154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, validX, trainy, validy = train_test_split(images, labels, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6562c13-55a6-4de8-872e-3432c53c7bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1100, 50, 50, 1), (276, 50, 50, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape, validX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a784a344-2cf0-4f79-a381-e5b909ee79ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "35/35 [==============================] - 2s 39ms/step - loss: 3.0487 - accuracy: 0.5745 - val_loss: 0.6116 - val_accuracy: 0.7029\n",
      "INFO:tensorflow:Assets written to: face-mask-detection-model\\assets\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 1s 35ms/step - loss: 0.5478 - accuracy: 0.7264 - val_loss: 0.4435 - val_accuracy: 0.8116\n",
      "INFO:tensorflow:Assets written to: face-mask-detection-model\\assets\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 1s 36ms/step - loss: 0.4311 - accuracy: 0.8100 - val_loss: 0.4358 - val_accuracy: 0.8080\n",
      "INFO:tensorflow:Assets written to: face-mask-detection-model\\assets\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - 1s 37ms/step - loss: 0.3436 - accuracy: 0.8555 - val_loss: 0.3082 - val_accuracy: 0.8623\n",
      "INFO:tensorflow:Assets written to: face-mask-detection-model\\assets\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - 1s 36ms/step - loss: 0.3056 - accuracy: 0.8855 - val_loss: 0.3696 - val_accuracy: 0.8333\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - 1s 39ms/step - loss: 0.2933 - accuracy: 0.8864 - val_loss: 0.2869 - val_accuracy: 0.8732\n",
      "INFO:tensorflow:Assets written to: face-mask-detection-model\\assets\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - 1s 36ms/step - loss: 0.2233 - accuracy: 0.9182 - val_loss: 0.3520 - val_accuracy: 0.8732\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - 1s 36ms/step - loss: 0.1933 - accuracy: 0.9218 - val_loss: 0.2336 - val_accuracy: 0.9130\n",
      "INFO:tensorflow:Assets written to: face-mask-detection-model\\assets\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - 1s 38ms/step - loss: 0.1768 - accuracy: 0.9373 - val_loss: 0.2247 - val_accuracy: 0.9167\n",
      "INFO:tensorflow:Assets written to: face-mask-detection-model\\assets\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - 1s 37ms/step - loss: 0.2074 - accuracy: 0.9218 - val_loss: 0.2452 - val_accuracy: 0.9058\n"
     ]
    }
   ],
   "source": [
    "# The checkpointing callback function\n",
    "checkpoint = ModelCheckpoint(\"face-mask-detection-model\", monitor = \"val_loss\", verbose = 0, save_best_only = True)\n",
    "# Train the model and checkpoint the best one\n",
    "history = model.fit(trainX, trainy, epochs = 10, validation_data = (validX, validy), callbacks = [checkpoint], verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ea5667-d94b-4aae-9bde-dc3e3816bcce",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c34e337-40ed-4320-ad1d-2ef0929c84cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc799094-5a3b-4417-9032-dce353bff7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curves\n",
    "x = range(1, 11)\n",
    "plt.plot(x, history.history[\"loss\"])\n",
    "plt.plot(x, history.history[\"val_loss\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curves\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36277882-d28f-406f-864b-10905bdb344b",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f36a652-7d31-4ecf-976f-14f72bbc434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3b0d07f-5731-4571-a2bf-7d18b39bbcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model\n",
    "bestModel = load_model(\"face-mask-detection-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0095d737-532c-41c2-899f-4d6d876632ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validation Loss, Validation Accuracy]:\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.2247 - accuracy: 0.9167\n",
      "[0.2246711701154709, 0.9166666865348816]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the best model\n",
    "print(\"[Validation Loss, Validation Accuracy]:\")\n",
    "print(bestModel.evaluate(validX, validy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3644ac-1ed3-45c2-baa6-84d0d0dc3d77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
